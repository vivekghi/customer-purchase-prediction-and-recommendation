{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sagemaker built in Algo - Factorization Machine we will build the recommender system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use the data prepared in previous script as starting point\n",
    "### We will use Sagemaker's inbuilt algorithm, Factorization Machine to build a recommender system\n",
    "### FM expects input sparse data in recordio protobuf format\n",
    "### The sparse matrix will be prepared with customerid, article id and product group name as categorical features and text embeddings through the description of the product\n",
    "### We will built a real time predictor for testing in Sagemaker and also create a batch transformer for processing multiple records through a batch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T12:00:00.070561Z",
     "iopub.status.busy": "2021-11-16T12:00:00.070128Z",
     "iopub.status.idle": "2021-11-16T12:00:00.775776Z",
     "shell.execute_reply": "2021-11-16T12:00:00.774685Z",
     "shell.execute_reply.started": "2021-11-16T12:00:00.070502Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "#import sagemaker\n",
    "#import sagemaker.amazon.common as smac\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack, save_npz, load_npz\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('max_colwidth', 50)  # default is 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T12:00:00.781449Z",
     "iopub.status.busy": "2021-11-16T12:00:00.780992Z",
     "iopub.status.idle": "2021-11-16T12:00:00.787939Z",
     "shell.execute_reply": "2021-11-16T12:00:00.786970Z",
     "shell.execute_reply.started": "2021-11-16T12:00:00.781405Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.20.3\n",
      "pandas version: 1.0.1\n"
     ]
    }
   ],
   "source": [
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"pandas version:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset\n",
    "### The data was already created in notebook#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T12:00:00.790291Z",
     "iopub.status.busy": "2021-11-16T12:00:00.789859Z",
     "iopub.status.idle": "2021-11-16T12:00:03.984668Z",
     "shell.execute_reply": "2021-11-16T12:00:03.983575Z",
     "shell.execute_reply.started": "2021-11-16T12:00:00.790249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 3347127 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>detail_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1836366</th>\n",
       "      <td>1836366</td>\n",
       "      <td>415107</td>\n",
       "      <td>568597007</td>\n",
       "      <td>1</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>Suit trousers in a stretch weave with a regula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014691</th>\n",
       "      <td>1014691</td>\n",
       "      <td>197828</td>\n",
       "      <td>832453003</td>\n",
       "      <td>1</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Fitted, off-the-shoulder top in smocked cotton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889016</th>\n",
       "      <td>889016</td>\n",
       "      <td>170254</td>\n",
       "      <td>821746001</td>\n",
       "      <td>1</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>Sports tights in fast-drying functional fabric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590949</th>\n",
       "      <td>2590949</td>\n",
       "      <td>686243</td>\n",
       "      <td>562245018</td>\n",
       "      <td>1</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>5-pocket jeans in washed, superstretch denim w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283356</th>\n",
       "      <td>1283356</td>\n",
       "      <td>260467</td>\n",
       "      <td>811925011</td>\n",
       "      <td>1</td>\n",
       "      <td>Swimwear</td>\n",
       "      <td>Lined, non-wired bikini top with wide shoulder...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index  customer_id  article_id  rating  product_group_name  \\\n",
       "1836366  1836366       415107   568597007       1  Garment Lower body   \n",
       "1014691  1014691       197828   832453003       1  Garment Upper body   \n",
       "889016    889016       170254   821746001       1  Garment Lower body   \n",
       "2590949  2590949       686243   562245018       1  Garment Lower body   \n",
       "1283356  1283356       260467   811925011       1            Swimwear   \n",
       "\n",
       "                                               detail_desc  \n",
       "1836366  Suit trousers in a stretch weave with a regula...  \n",
       "1014691  Fitted, off-the-shoulder top in smocked cotton...  \n",
       "889016   Sports tights in fast-drying functional fabric...  \n",
       "2590949  5-pocket jeans in washed, superstretch denim w...  \n",
       "1283356  Lined, non-wired bikini top with wide shoulder...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set \"usecols\" to prevent the following error:\n",
    "# ParserError: Error tokenizing data. C error: Expected 15 fields in line 1598, saw 22\n",
    "\n",
    "df_rank = pd.read_csv(\"fm_preprocessed_filtered_with_attributes.csv\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Total records:\", df_rank.shape[0], \"\\n\")\n",
    "#print(\"Sample records:\\n\")\n",
    "df_rank.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank[\"detail_desc\"].fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T12:00:05.943221Z",
     "iopub.status.busy": "2021-11-16T12:00:05.942266Z",
     "iopub.status.idle": "2021-11-16T12:00:06.211860Z",
     "shell.execute_reply": "2021-11-16T12:00:06.210727Z",
     "shell.execute_reply.started": "2021-11-16T12:00:05.943168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique customers: 680578\n",
      "Unique products: 1684\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique customers:\", df_rank[\"customer_id\"].nunique())\n",
    "print(\"Unique products:\", df_rank[\"article_id\"].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the sparse matrix\n",
    "#### For categorical columns use OneHotEncoder\n",
    "#### For text columns use TfIdf for text embeddings from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3347127x682272 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10041381 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(handle_unknown = \"ignore\")\n",
    "ohe_cols = [\"customer_id\", \"article_id\",\"product_group_name\"]\n",
    "ohe_features = ohe.fit_transform(df_rank[ohe_cols])\n",
    "ohe_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rank.detail_desc.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3347127x482 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 65490369 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=2)  \n",
    "vectorizer.fit(df_rank[\"detail_desc\"].unique())\n",
    "tfidf_features = vectorizer.transform(df_rank[\"detail_desc\"])\n",
    "tfidf_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3347127x682754 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 75531750 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = hstack([ohe_features,tfidf_features], format=\"csr\", dtype=\"float32\")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T12:00:06.365078Z",
     "iopub.status.busy": "2021-11-16T12:00:06.364169Z",
     "iopub.status.idle": "2021-11-16T12:00:06.538229Z",
     "shell.execute_reply": "2021-11-16T12:00:06.537281Z",
     "shell.execute_reply.started": "2021-11-16T12:00:06.365026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 5., 5., 5.], dtype=float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_rank[\"rating\"].values.astype(\"float32\")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T12:00:06.540439Z",
     "iopub.status.busy": "2021-11-16T12:00:06.539823Z",
     "iopub.status.idle": "2021-11-16T12:00:06.561893Z",
     "shell.execute_reply": "2021-11-16T12:00:06.560938Z",
     "shell.execute_reply.started": "2021-11-16T12:00:06.540396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total elements: 2285264347758\n",
      "Non-zero elements: 75531750\n",
      "Sparsity: 99.9967 %\n"
     ]
    }
   ],
   "source": [
    "total = X.shape[0] * X.shape[1]\n",
    "non_zero = X.nnz\n",
    "sparsity = (total - non_zero) / total\n",
    "\n",
    "print(\"Total elements:\", total)\n",
    "print(\"Non-zero elements:\", non_zero)\n",
    "print(\"Sparsity:\", round(sparsity*100, 4), \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spilt the data in training and testing set. The rating is the prediction label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T12:00:06.563421Z",
     "iopub.status.busy": "2021-11-16T12:00:06.563153Z",
     "iopub.status.idle": "2021-11-16T12:00:06.621047Z",
     "shell.execute_reply": "2021-11-16T12:00:06.620351Z",
     "shell.execute_reply.started": "2021-11-16T12:00:06.563392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (2677701, 682754)\n",
      "Shape of y_train: (2677701,) \n",
      "\n",
      "Shape of X_test: (669426, 682754)\n",
      "Shape of y_test: (669426,)\n"
     ]
    }
   ],
   "source": [
    "# By default, shuffle=True.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    random_state=73)           \n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape, \"\\n\")\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-16T12:00:06.625973Z",
     "iopub.status.busy": "2021-11-16T12:00:06.625446Z",
     "iopub.status.idle": "2021-11-16T12:00:06.665598Z",
     "shell.execute_reply": "2021-11-16T12:00:06.664599Z",
     "shell.execute_reply.started": "2021-11-16T12:00:06.625924Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_dim = X.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create sparse RecordIO file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def write_sparse_recordio_file (filename, X, y=None):\n",
    "    with open(filename, 'wb') as f:\n",
    "        smac.write_spmatrix_to_sparse_tensor (f, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to upload file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to upload file to S3.\n",
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/guide/s3-uploading-files.html\n",
    "# https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.upload_fileobj\n",
    "\n",
    "def upload_to_s3(filename, bucket, prefix, key):\n",
    "    with open(filename,'rb') as f: # Read in binary mode\n",
    "        boto3.Session().resource('s3').Bucket(bucket).Object(f\"{prefix}/{key}\").upload_fileobj(f)\n",
    "        return f\"s3://{bucket}/{prefix}/{key}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_sparse_recordio_file(\"fm_train_filtered_sparse.recordio\", X_train, y_train)\n",
    "write_sparse_recordio_file(\"fm_test_filtered_sparse.recordio\", X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading the train and test RecordIO files to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker version: 2.70.0\n",
      "Region: ap-south-1\n",
      "Bucket: sagemaker-ap-south-1-659144925604\n",
      "train file location: s3://sagemaker-ap-south-1-659144925604/filteredfm/fm_train_filtered_sparse.recordio\n",
      "test file location: s3://sagemaker-ap-south-1-659144925604/filteredfm/fm_test_filtered_sparse.recordio\n",
      "model output location: s3://sagemaker-ap-south-1-659144925604/filteredfm/output\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "prefix = \"filteredfm\"\n",
    "train_key = \"fm_train_filtered_sparse.recordio\"\n",
    "test_key = \"fm_test_filtered_sparse.recordio\"\n",
    "output_location = f\"s3://{bucket}/{prefix}/output\"\n",
    "\n",
    "train_file_location = upload_to_s3(\"fm_train_filtered_sparse.recordio\", bucket, prefix, train_key)\n",
    "test_file_location = upload_to_s3(\"fm_test_filtered_sparse.recordio\", bucket, prefix, test_key)\n",
    "\n",
    "print(\"SageMaker version:\", sagemaker.__version__)\n",
    "print(\"Region:\", region)\n",
    "print(\"Bucket:\", bucket)\n",
    "print(\"train file location:\", train_file_location)\n",
    "print(\"test file location:\", test_file_location)\n",
    "print(\"model output location:\", output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fm-job-recommender-v1'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = 'fm-job-recommender-v1'\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint uri: None\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/aws-samples/amazon-sagemaker-managed-spot-training/blob/main/xgboost_built_in_managed_spot_training_checkpointing/xgboost_built_in_managed_spot_training_checkpointing.ipynb\n",
    "    \n",
    "use_spot_instances = False\n",
    "max_run = 3600                                   # set to 60 mins\n",
    "max_wait = 3600 if use_spot_instances else None  # set to 60 mins (must be equal or greater than max_run)\n",
    "   \n",
    "checkpoint_s3_uri = (f\"s3://{bucket}/{prefix}/checkpoints/{job_name}\" if use_spot_instances\n",
    "                     else None)\n",
    "    \n",
    "print(f\"Checkpoint uri: {checkpoint_s3_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'991648021394.dkr.ecr.ap-south-1.amazonaws.com/factorization-machines:1'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "container = sagemaker.image_uris.retrieve(\"factorization-machines\", region=region)\n",
    "container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define estimator as built in Factorization machine model in Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(    \n",
    "    container,\n",
    "    role,\n",
    "    instance_count = 1,\n",
    "    instance_type = \"ml.m4.xlarge\",   # Or \"ml.c5.xlarge\",\n",
    "    output_path = output_location,\n",
    "    sagemaker_session = sess,\n",
    "    base_job_name = job_name,\n",
    "    use_spot_instances = use_spot_instances,\n",
    "    max_run = max_run,\n",
    "    max_wait = max_wait,\n",
    "    checkpoint_s3_uri = checkpoint_s3_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "682754"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the hyperparameters of FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_dim': 682754,\n",
       " 'num_factors': 64,\n",
       " 'predictor_type': 'regressor',\n",
       " 'epochs': 5,\n",
       " 'mini_batch_size': 2000}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.set_hyperparameters(\n",
    "    feature_dim = feature_dim,\n",
    "    num_factors = 64,  \n",
    "    predictor_type = \"regressor\",\n",
    "    epochs = 5,      \n",
    "    mini_batch_size = 2000,  \n",
    ")\n",
    "\n",
    "estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start trainig job in Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-17 09:34:51 Starting - Starting the training job...\n",
      "2022-04-17 09:35:16 Starting - Preparing the instances for trainingProfilerReport-1650188091: InProgress\n",
      ".........\n",
      "2022-04-17 09:36:36 Downloading - Downloading input data...\n",
      "2022-04-17 09:37:15 Training - Downloading the training image.....\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/jsonref.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, MutableMapping, Sequence\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:87: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:120: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:04 INFO 140272607053632 integration.py:636] worker started\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:04 INFO 140272607053632] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-conf.json: {'epochs': 1, 'mini_batch_size': '1000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0'}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:04 INFO 140272607053632] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'epochs': '5', 'feature_dim': '682754', 'mini_batch_size': '2000', 'num_factors': '64', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:04 INFO 140272607053632] Final configuration: {'epochs': '5', 'mini_batch_size': '2000', 'use_bias': 'true', 'use_linear': 'true', 'bias_lr': '0.1', 'linear_lr': '0.001', 'factors_lr': '0.0001', 'bias_wd': '0.01', 'linear_wd': '0.001', 'factors_wd': '0.00001', 'bias_init_method': 'normal', 'bias_init_sigma': '0.01', 'linear_init_method': 'normal', 'linear_init_sigma': '0.01', 'factors_init_method': 'normal', 'factors_init_sigma': '0.001', 'batch_metrics_publish_interval': '500', '_data_format': 'record', '_kvstore': 'auto', '_learning_rate': '1.0', '_log_level': 'info', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_optimizer': 'adam', '_tuning_objective_metric': '', '_use_full_symbolic': 'true', '_wd': '1.0', 'feature_dim': '682754', 'num_factors': '64', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:04 WARNING 140272607053632] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:04 INFO 140272607053632] Using default worker.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:04 INFO 140272607053632] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:38:04.274] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:38:04.329] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 83, \"num_examples\": 1, \"num_bytes\": 425516}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:04 INFO 140272607053632] nvidia-smi: took 0.041 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:04 INFO 140272607053632] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:04 INFO 140272607053632] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:04 INFO 140272607053632] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:04 INFO 140272607053632] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650188284.2448633, \"EndTime\": 1650188284.3815572, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 70.87397575378418, \"count\": 1, \"min\": 70.87397575378418, \"max\": 70.87397575378418}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650188284.3817966, \"EndTime\": 1650188284.3821032, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2000.0, \"count\": 1, \"min\": 2000, \"max\": 2000}, \"Total Batches Seen\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Max Records Seen Between Resets\": {\"sum\": 2000.0, \"count\": 1, \"min\": 2000, \"max\": 2000}, \"Max Batches Seen Between Resets\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[09:38:04] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.206339.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[09:38:04] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.206339.0/AL2_x86_64/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:07 INFO 140272607053632] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=1.272583014697617\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:07 INFO 140272607053632] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=1.619467529296875\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:07 INFO 140272607053632] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=1.179954833984375\u001b[0m\n",
      "\n",
      "2022-04-17 09:38:15 Training - Training image download completed. Training in progress.\u001b[34m[04/17/2022 09:38:31 INFO 140272607053632] Iter[0] Batch [500]#011Speed: 41601.57 samples/sec\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:31 INFO 140272607053632] #quality_metric: host=algo-1, epoch=0, batch=500 train rmse <loss>=0.4692938436265489\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:31 INFO 140272607053632] #quality_metric: host=algo-1, epoch=0, batch=500 train mse <loss>=0.22023671166577977\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:31 INFO 140272607053632] #quality_metric: host=algo-1, epoch=0, batch=500 train absolute_loss <loss>=0.30461255918339103\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:54 INFO 140272607053632] Iter[0] Batch [1000]#011Speed: 42516.70 samples/sec\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:54 INFO 140272607053632] #quality_metric: host=algo-1, epoch=0, batch=1000 train rmse <loss>=0.45980073293551615\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:54 INFO 140272607053632] #quality_metric: host=algo-1, epoch=0, batch=1000 train mse <loss>=0.21141671400803785\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:38:54 INFO 140272607053632] #quality_metric: host=algo-1, epoch=0, batch=1000 train absolute_loss <loss>=0.2967999904148586\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:39:11.533] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 64632, \"num_examples\": 1339, \"num_bytes\": 569601776}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:11 INFO 140272607053632] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=0.45670389528052735\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:11 INFO 140272607053632] #quality_metric: host=algo-1, epoch=0, train mse <loss>=0.2085784479644069\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:11 INFO 140272607053632] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=0.29465985592877003\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650188284.3817244, \"EndTime\": 1650188351.534572, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"update.time\": {\"sum\": 67151.58534049988, \"count\": 1, \"min\": 67151.58534049988, \"max\": 67151.58534049988}}}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:11 INFO 140272607053632] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650188284.382939, \"EndTime\": 1650188351.53493, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 2679701.0, \"count\": 1, \"min\": 2679701, \"max\": 2679701}, \"Total Batches Seen\": {\"sum\": 1340.0, \"count\": 1, \"min\": 1340, \"max\": 1340}, \"Max Records Seen Between Resets\": {\"sum\": 2677701.0, \"count\": 1, \"min\": 2677701, \"max\": 2677701}, \"Max Batches Seen Between Resets\": {\"sum\": 1339.0, \"count\": 1, \"min\": 1339, \"max\": 1339}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 2677701.0, \"count\": 1, \"min\": 2677701, \"max\": 2677701}, \"Number of Batches Since Last Reset\": {\"sum\": 1339.0, \"count\": 1, \"min\": 1339, \"max\": 1339}}}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:11 INFO 140272607053632] #throughput_metric: host=algo-1, train throughput=39875.13123866144 records/second\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:11 INFO 140272607053632] #quality_metric: host=algo-1, epoch=1, batch=0 train rmse <loss>=0.4635431516244941\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:11 INFO 140272607053632] #quality_metric: host=algo-1, epoch=1, batch=0 train mse <loss>=0.21487225341796876\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:11 INFO 140272607053632] #quality_metric: host=algo-1, epoch=1, batch=0 train absolute_loss <loss>=0.28852325439453125\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:35 INFO 140272607053632] Iter[1] Batch [500]#011Speed: 42677.07 samples/sec\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:35 INFO 140272607053632] #quality_metric: host=algo-1, epoch=1, batch=500 train rmse <loss>=0.44104145320467053\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:35 INFO 140272607053632] #quality_metric: host=algo-1, epoch=1, batch=500 train mse <loss>=0.19451756344488758\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:35 INFO 140272607053632] #quality_metric: host=algo-1, epoch=1, batch=500 train absolute_loss <loss>=0.2841358051718828\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:58 INFO 140272607053632] Iter[1] Batch [1000]#011Speed: 42817.66 samples/sec\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:58 INFO 140272607053632] #quality_metric: host=algo-1, epoch=1, batch=1000 train rmse <loss>=0.4381583189124921\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:58 INFO 140272607053632] #quality_metric: host=algo-1, epoch=1, batch=1000 train mse <loss>=0.1919827124322211\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:39:58 INFO 140272607053632] #quality_metric: host=algo-1, epoch=1, batch=1000 train absolute_loss <loss>=0.2822068882502995\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:40:14.813] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 4, \"duration\": 63275, \"num_examples\": 1339, \"num_bytes\": 569601776}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:40:14 INFO 140272607053632] #quality_metric: host=algo-1, epoch=1, train rmse <loss>=0.43659588743810157\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:40:14 INFO 140272607053632] #quality_metric: host=algo-1, epoch=1, train mse <loss>=0.19061596892786348\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:40:14 INFO 140272607053632] #quality_metric: host=algo-1, epoch=1, train absolute_loss <loss>=0.281163693018508\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650188351.5346901, \"EndTime\": 1650188414.813916, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 63278.58519554138, \"count\": 1, \"min\": 63278.58519554138, \"max\": 63278.58519554138}}}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:40:14 INFO 140272607053632] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650188351.5352921, \"EndTime\": 1650188414.8142674, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 5357402.0, \"count\": 1, \"min\": 5357402, \"max\": 5357402}, \"Total Batches Seen\": {\"sum\": 2679.0, \"count\": 1, \"min\": 2679, \"max\": 2679}, \"Max Records Seen Between Resets\": {\"sum\": 2677701.0, \"count\": 1, \"min\": 2677701, \"max\": 2677701}, \"Max Batches Seen Between Resets\": {\"sum\": 1339.0, \"count\": 1, \"min\": 1339, \"max\": 1339}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 2677701.0, \"count\": 1, \"min\": 2677701, \"max\": 2677701}, \"Number of Batches Since Last Reset\": {\"sum\": 1339.0, \"count\": 1, \"min\": 1339, \"max\": 1339}}}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:40:14 INFO 140272607053632] #throughput_metric: host=algo-1, train throughput=42315.68081384094 records/second\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:40:14 INFO 140272607053632] #quality_metric: host=algo-1, epoch=2, batch=0 train rmse <loss>=0.44906014523456206\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:40:14 INFO 140272607053632] #quality_metric: host=algo-1, epoch=2, batch=0 train mse <loss>=0.20165501403808594\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:40:14 INFO 140272607053632] #quality_metric: host=algo-1, epoch=2, batch=0 train absolute_loss <loss>=0.2780626831054688\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:40:38 INFO 140272607053632] Iter[2] Batch [500]#011Speed: 43306.01 samples/sec\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:40:38 INFO 140272607053632] #quality_metric: host=algo-1, epoch=2, batch=500 train rmse <loss>=0.4259015202845752\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:40:38 INFO 140272607053632] #quality_metric: host=algo-1, epoch=2, batch=500 train mse <loss>=0.1813921049807124\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:40:38 INFO 140272607053632] #quality_metric: host=algo-1, epoch=2, batch=500 train absolute_loss <loss>=0.2734993174356853\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:01 INFO 140272607053632] Iter[2] Batch [1000]#011Speed: 42394.06 samples/sec\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:01 INFO 140272607053632] #quality_metric: host=algo-1, epoch=2, batch=1000 train rmse <loss>=0.4232149483358973\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:01 INFO 140272607053632] #quality_metric: host=algo-1, epoch=2, batch=1000 train mse <loss>=0.1791108924949562\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:01 INFO 140272607053632] #quality_metric: host=algo-1, epoch=2, batch=1000 train absolute_loss <loss>=0.27140036150982805\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:41:18.045] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 6, \"duration\": 63220, \"num_examples\": 1339, \"num_bytes\": 569601776}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:18 INFO 140272607053632] #quality_metric: host=algo-1, epoch=2, train rmse <loss>=0.4218416325113855\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:18 INFO 140272607053632] #quality_metric: host=algo-1, epoch=2, train mse <loss>=0.17795036291987082\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:18 INFO 140272607053632] #quality_metric: host=algo-1, epoch=2, train absolute_loss <loss>=0.2703015447364448\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650188414.8140385, \"EndTime\": 1650188478.0465975, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 63225.4843711853, \"count\": 1, \"min\": 63225.4843711853, \"max\": 63225.4843711853}}}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:18 INFO 140272607053632] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650188414.8210733, \"EndTime\": 1650188478.046943, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 8035103.0, \"count\": 1, \"min\": 8035103, \"max\": 8035103}, \"Total Batches Seen\": {\"sum\": 4018.0, \"count\": 1, \"min\": 4018, \"max\": 4018}, \"Max Records Seen Between Resets\": {\"sum\": 2677701.0, \"count\": 1, \"min\": 2677701, \"max\": 2677701}, \"Max Batches Seen Between Resets\": {\"sum\": 1339.0, \"count\": 1, \"min\": 1339, \"max\": 1339}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 2677701.0, \"count\": 1, \"min\": 2677701, \"max\": 2677701}, \"Number of Batches Since Last Reset\": {\"sum\": 1339.0, \"count\": 1, \"min\": 1339, \"max\": 1339}}}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:18 INFO 140272607053632] #throughput_metric: host=algo-1, train throughput=42351.23061503031 records/second\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:18 INFO 140272607053632] #quality_metric: host=algo-1, epoch=3, batch=0 train rmse <loss>=0.4344566828268725\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:18 INFO 140272607053632] #quality_metric: host=algo-1, epoch=3, batch=0 train mse <loss>=0.1887526092529297\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:18 INFO 140272607053632] #quality_metric: host=algo-1, epoch=3, batch=0 train absolute_loss <loss>=0.280539794921875\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:41 INFO 140272607053632] Iter[3] Batch [500]#011Speed: 42969.29 samples/sec\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:41 INFO 140272607053632] #quality_metric: host=algo-1, epoch=3, batch=500 train rmse <loss>=0.4129934971564815\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:41 INFO 140272607053632] #quality_metric: host=algo-1, epoch=3, batch=500 train mse <loss>=0.17056362869354066\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:41:41 INFO 140272607053632] #quality_metric: host=algo-1, epoch=3, batch=500 train absolute_loss <loss>=0.26320722550260806\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:05 INFO 140272607053632] Iter[3] Batch [1000]#011Speed: 42185.08 samples/sec\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:05 INFO 140272607053632] #quality_metric: host=algo-1, epoch=3, batch=1000 train rmse <loss>=0.41062166312282017\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:05 INFO 140272607053632] #quality_metric: host=algo-1, epoch=3, batch=1000 train mse <loss>=0.16861015022575082\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:05 INFO 140272607053632] #quality_metric: host=algo-1, epoch=3, batch=1000 train absolute_loss <loss>=0.26128537542169744\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:42:21.081] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 8, \"duration\": 63029, \"num_examples\": 1339, \"num_bytes\": 569601776}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:21 INFO 140272607053632] #quality_metric: host=algo-1, epoch=3, train rmse <loss>=0.40945734165210884\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:21 INFO 140272607053632] #quality_metric: host=algo-1, epoch=3, train mse <loss>=0.16765531463281177\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:21 INFO 140272607053632] #quality_metric: host=algo-1, epoch=3, train absolute_loss <loss>=0.26030102025118224\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650188478.0467052, \"EndTime\": 1650188541.0824513, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 63033.682107925415, \"count\": 1, \"min\": 63033.682107925415, \"max\": 63033.682107925415}}}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:21 INFO 140272607053632] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650188478.048742, \"EndTime\": 1650188541.082643, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10712804.0, \"count\": 1, \"min\": 10712804, \"max\": 10712804}, \"Total Batches Seen\": {\"sum\": 5357.0, \"count\": 1, \"min\": 5357, \"max\": 5357}, \"Max Records Seen Between Resets\": {\"sum\": 2677701.0, \"count\": 1, \"min\": 2677701, \"max\": 2677701}, \"Max Batches Seen Between Resets\": {\"sum\": 1339.0, \"count\": 1, \"min\": 1339, \"max\": 1339}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 2677701.0, \"count\": 1, \"min\": 2677701, \"max\": 2677701}, \"Number of Batches Since Last Reset\": {\"sum\": 1339.0, \"count\": 1, \"min\": 1339, \"max\": 1339}}}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:21 INFO 140272607053632] #throughput_metric: host=algo-1, train throughput=42480.24378514322 records/second\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:21 INFO 140272607053632] #quality_metric: host=algo-1, epoch=4, batch=0 train rmse <loss>=0.42242621686089304\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:21 INFO 140272607053632] #quality_metric: host=algo-1, epoch=4, batch=0 train mse <loss>=0.17844390869140625\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:21 INFO 140272607053632] #quality_metric: host=algo-1, epoch=4, batch=0 train absolute_loss <loss>=0.2764207153320313\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:44 INFO 140272607053632] Iter[4] Batch [500]#011Speed: 42540.17 samples/sec\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:44 INFO 140272607053632] #quality_metric: host=algo-1, epoch=4, batch=500 train rmse <loss>=0.40235544768727083\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:44 INFO 140272607053632] #quality_metric: host=algo-1, epoch=4, batch=500 train mse <loss>=0.16188990628362415\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:42:44 INFO 140272607053632] #quality_metric: host=algo-1, epoch=4, batch=500 train absolute_loss <loss>=0.25426833868883325\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:43:08 INFO 140272607053632] Iter[4] Batch [1000]#011Speed: 41659.88 samples/sec\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:43:08 INFO 140272607053632] #quality_metric: host=algo-1, epoch=4, batch=1000 train rmse <loss>=0.4002369521160322\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:43:08 INFO 140272607053632] #quality_metric: host=algo-1, epoch=4, batch=1000 train mse <loss>=0.16018961783913108\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:43:08 INFO 140272607053632] #quality_metric: host=algo-1, epoch=4, batch=1000 train absolute_loss <loss>=0.2525309875061462\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:43:24.502] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 10, \"duration\": 63404, \"num_examples\": 1339, \"num_bytes\": 569601776}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:43:24 INFO 140272607053632] #quality_metric: host=algo-1, epoch=4, train rmse <loss>=0.3992254053811884\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:43:24 INFO 140272607053632] #quality_metric: host=algo-1, epoch=4, train mse <loss>=0.15938092430177422\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:43:24 INFO 140272607053632] #quality_metric: host=algo-1, epoch=4, train absolute_loss <loss>=0.2516639451588865\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:43:24 INFO 140272607053632] #quality_metric: host=algo-1, train rmse <loss>=0.3992254053811884\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:43:24 INFO 140272607053632] #quality_metric: host=algo-1, train mse <loss>=0.15938092430177422\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:43:24 INFO 140272607053632] #quality_metric: host=algo-1, train absolute_loss <loss>=0.2516639451588865\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650188541.0825138, \"EndTime\": 1650188604.503546, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"update.time\": {\"sum\": 63409.30914878845, \"count\": 1, \"min\": 63409.30914878845, \"max\": 63409.30914878845}}}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:43:24 INFO 140272607053632] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650188541.094196, \"EndTime\": 1650188604.5038846, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 13390505.0, \"count\": 1, \"min\": 13390505, \"max\": 13390505}, \"Total Batches Seen\": {\"sum\": 6696.0, \"count\": 1, \"min\": 6696, \"max\": 6696}, \"Max Records Seen Between Resets\": {\"sum\": 2677701.0, \"count\": 1, \"min\": 2677701, \"max\": 2677701}, \"Max Batches Seen Between Resets\": {\"sum\": 1339.0, \"count\": 1, \"min\": 1339, \"max\": 1339}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 2677701.0, \"count\": 1, \"min\": 2677701, \"max\": 2677701}, \"Number of Batches Since Last Reset\": {\"sum\": 1339.0, \"count\": 1, \"min\": 1339, \"max\": 1339}}}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:43:24 INFO 140272607053632] #throughput_metric: host=algo-1, train throughput=42228.49423208088 records/second\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:43:24 WARNING 140272607053632] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:43:24 INFO 140272607053632] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650188604.503643, \"EndTime\": 1650188604.6732502, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 168.9436435699463, \"count\": 1, \"min\": 168.9436435699463, \"max\": 168.9436435699463}}}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:43:25 INFO 140272607053632] Saved checkpoint to \"/tmp/tmps2gaau_q/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:43:26.076] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 321801, \"num_examples\": 1, \"num_bytes\": 425672}\u001b[0m\n",
      "\n",
      "2022-04-17 09:44:25 Uploading - Uploading generated training model\u001b[34m[04/17/2022 09:44:18 INFO 140272607053632 integration.py:636] worker closed\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:44:18.995] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 52918, \"num_examples\": 335, \"num_bytes\": 142363840}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650188606.075855, \"EndTime\": 1650188658.995952, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"test_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 669426.0, \"count\": 1, \"min\": 669426, \"max\": 669426}, \"Total Batches Seen\": {\"sum\": 335.0, \"count\": 1, \"min\": 335, \"max\": 335}, \"Max Records Seen Between Resets\": {\"sum\": 669426.0, \"count\": 1, \"min\": 669426, \"max\": 669426}, \"Max Batches Seen Between Resets\": {\"sum\": 335.0, \"count\": 1, \"min\": 335, \"max\": 335}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 669426.0, \"count\": 1, \"min\": 669426, \"max\": 669426}, \"Number of Batches Since Last Reset\": {\"sum\": 335.0, \"count\": 1, \"min\": 335, \"max\": 335}}}\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:44:18 INFO 140272607053632] #test_score (algo-1) : ('rmse', 0.4337314122313325)\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:44:18 INFO 140272607053632] #test_score (algo-1) : ('mse', 0.18812293795618606)\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:44:18 INFO 140272607053632] #test_score (algo-1) : ('absolute_loss', 0.2837177136691342)\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:44:18 INFO 140272607053632] #quality_metric: host=algo-1, test rmse <loss>=0.4337314122313325\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:44:18 INFO 140272607053632] #quality_metric: host=algo-1, test mse <loss>=0.18812293795618606\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:44:18 INFO 140272607053632] #quality_metric: host=algo-1, test absolute_loss <loss>=0.2837177136691342\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650188604.6734204, \"EndTime\": 1650188658.9969072, \"Dimensions\": {\"Algorithm\": \"factorization-machines\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"setuptime\": {\"sum\": 48.96283149719238, \"count\": 1, \"min\": 48.96283149719238, \"max\": 48.96283149719238}, \"totaltime\": {\"sum\": 374813.5964870453, \"count\": 1, \"min\": 374813.5964870453, \"max\": 374813.5964870453}}}\u001b[0m\n",
      "\n",
      "2022-04-17 09:45:17 Completed - Training job completed\n",
      "ProfilerReport-1650188091: NoIssuesFound\n",
      "Training seconds: 505\n",
      "Billable seconds: 505\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train':train_file_location, \n",
    "               'test':test_file_location})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TrainingJobName': 'fm-job-recommender-v1-2022-04-17-09-34-51-355',\n",
       " 'TrainingJobArn': 'arn:aws:sagemaker:ap-south-1:659144925604:training-job/fm-job-recommender-v1-2022-04-17-09-34-51-355',\n",
       " 'ModelArtifacts': {'S3ModelArtifacts': 's3://sagemaker-ap-south-1-659144925604/filteredfm/output/fm-job-recommender-v1-2022-04-17-09-34-51-355/output/model.tar.gz'},\n",
       " 'TrainingJobStatus': 'Completed',\n",
       " 'SecondaryStatus': 'Completed',\n",
       " 'HyperParameters': {'epochs': '5',\n",
       "  'feature_dim': '682754',\n",
       "  'mini_batch_size': '2000',\n",
       "  'num_factors': '64',\n",
       "  'predictor_type': 'regressor'},\n",
       " 'AlgorithmSpecification': {'TrainingImage': '991648021394.dkr.ecr.ap-south-1.amazonaws.com/factorization-machines:1',\n",
       "  'TrainingInputMode': 'File',\n",
       "  'MetricDefinitions': [{'Name': 'train:rmse:epoch',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, epoch=\\\\S+, train rmse <loss>=(\\\\S+)'},\n",
       "   {'Name': 'train:progress',\n",
       "    'Regex': '#progress_metric: host=\\\\S+, completed (\\\\S+) %'},\n",
       "   {'Name': 'test:binary_f_beta',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, test binary_f_1.000 <score>=(\\\\S+)'},\n",
       "   {'Name': 'test:mse',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, test mse <loss>=(\\\\S+)'},\n",
       "   {'Name': 'train:binary_classification_accuracy:batch',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, epoch=\\\\S+, batch=\\\\S+ train binary_classification_accuracy <score>=(\\\\S+)'},\n",
       "   {'Name': 'train:mse:batch',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, epoch=\\\\S+, batch=\\\\S+ train mse <loss>=(\\\\S+)'},\n",
       "   {'Name': 'train:absolute_loss:epoch',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, epoch=\\\\S+, train absolute_loss <loss>=(\\\\S+)'},\n",
       "   {'Name': 'test:absolute_loss',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, test absolute_loss <loss>=(\\\\S+)'},\n",
       "   {'Name': 'train:mse',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, train mse <loss>=(\\\\S+)'},\n",
       "   {'Name': 'train:binary_f_beta:batch',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, epoch=\\\\S+, batch=\\\\S+ train binary_f_1.000 <score>=(\\\\S+)'},\n",
       "   {'Name': 'train:binary_classification_cross_entropy:epoch',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, epoch=\\\\S+, train binary_classification_cross_entropy <loss>=(\\\\S+)'},\n",
       "   {'Name': 'train:binary_f_beta',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, train binary_f_1.000 <score>=(\\\\S+)'},\n",
       "   {'Name': 'train:mse:epoch',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, epoch=\\\\S+, train mse <loss>=(\\\\S+)'},\n",
       "   {'Name': 'train:rmse:batch',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, epoch=\\\\S+, batch=\\\\S+ train rmse <loss>=(\\\\S+)'},\n",
       "   {'Name': 'train:binary_classification_cross_entropy',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, train binary_classification_cross_entropy <loss>=(\\\\S+)'},\n",
       "   {'Name': 'train:binary_f_beta:epoch',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, epoch=\\\\S+, train binary_f_1.000 <score>=(\\\\S+)'},\n",
       "   {'Name': 'train:rmse',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, train rmse <loss>=(\\\\S+)'},\n",
       "   {'Name': 'test:rmse',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, test rmse <loss>=(\\\\S+)'},\n",
       "   {'Name': 'train:binary_classification_accuracy:epoch',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, epoch=\\\\S+, train binary_classification_accuracy <score>=(\\\\S+)'},\n",
       "   {'Name': 'train:absolute_loss:batch',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, epoch=\\\\S+, batch=\\\\S+ train absolute_loss <loss>=(\\\\S+)'},\n",
       "   {'Name': 'train:binary_classification_accuracy',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, train binary_classification_accuracy <score>=(\\\\S+)'},\n",
       "   {'Name': 'test:binary_classification_cross_entropy',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, test binary_classification_cross_entropy <loss>=(\\\\S+)'},\n",
       "   {'Name': 'train:absolute_loss',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, train absolute_loss <loss>=(\\\\S+)'},\n",
       "   {'Name': 'train:throughput',\n",
       "    'Regex': '#throughput_metric: host=\\\\S+, train throughput=(\\\\S+) records/second'},\n",
       "   {'Name': 'test:binary_classification_accuracy',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, test binary_classification_accuracy <score>=(\\\\S+)'},\n",
       "   {'Name': 'train:binary_classification_cross_entropy:batch',\n",
       "    'Regex': '#quality_metric: host=\\\\S+, epoch=\\\\S+, batch=\\\\S+ train binary_classification_cross_entropy <loss>=(\\\\S+)'}],\n",
       "  'EnableSageMakerMetricsTimeSeries': False},\n",
       " 'RoleArn': 'arn:aws:iam::659144925604:role/service-role/AmazonSageMaker-ExecutionRole-20220320T214029',\n",
       " 'InputDataConfig': [{'ChannelName': 'train',\n",
       "   'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "     'S3Uri': 's3://sagemaker-ap-south-1-659144925604/filteredfm/fm_train_filtered_sparse.recordio',\n",
       "     'S3DataDistributionType': 'FullyReplicated'}},\n",
       "   'CompressionType': 'None',\n",
       "   'RecordWrapperType': 'None'},\n",
       "  {'ChannelName': 'test',\n",
       "   'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "     'S3Uri': 's3://sagemaker-ap-south-1-659144925604/filteredfm/fm_test_filtered_sparse.recordio',\n",
       "     'S3DataDistributionType': 'FullyReplicated'}},\n",
       "   'CompressionType': 'None',\n",
       "   'RecordWrapperType': 'None'}],\n",
       " 'OutputDataConfig': {'KmsKeyId': '',\n",
       "  'S3OutputPath': 's3://sagemaker-ap-south-1-659144925604/filteredfm/output'},\n",
       " 'ResourceConfig': {'InstanceType': 'ml.m4.xlarge',\n",
       "  'InstanceCount': 1,\n",
       "  'VolumeSizeInGB': 30},\n",
       " 'StoppingCondition': {'MaxRuntimeInSeconds': 3600},\n",
       " 'CreationTime': datetime.datetime(2022, 4, 17, 9, 34, 51, 510000, tzinfo=tzlocal()),\n",
       " 'TrainingStartTime': datetime.datetime(2022, 4, 17, 9, 36, 36, 966000, tzinfo=tzlocal()),\n",
       " 'TrainingEndTime': datetime.datetime(2022, 4, 17, 9, 45, 1, 116000, tzinfo=tzlocal()),\n",
       " 'LastModifiedTime': datetime.datetime(2022, 4, 17, 9, 45, 17, 69000, tzinfo=tzlocal()),\n",
       " 'SecondaryStatusTransitions': [{'Status': 'Starting',\n",
       "   'StartTime': datetime.datetime(2022, 4, 17, 9, 34, 51, 510000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2022, 4, 17, 9, 36, 36, 966000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Preparing the instances for training'},\n",
       "  {'Status': 'Downloading',\n",
       "   'StartTime': datetime.datetime(2022, 4, 17, 9, 36, 36, 966000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2022, 4, 17, 9, 37, 12, 591000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Downloading input data'},\n",
       "  {'Status': 'Training',\n",
       "   'StartTime': datetime.datetime(2022, 4, 17, 9, 37, 12, 591000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2022, 4, 17, 9, 44, 25, 317000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Training image download completed. Training in progress.'},\n",
       "  {'Status': 'Uploading',\n",
       "   'StartTime': datetime.datetime(2022, 4, 17, 9, 44, 25, 317000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2022, 4, 17, 9, 45, 1, 116000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Uploading generated training model'},\n",
       "  {'Status': 'Completed',\n",
       "   'StartTime': datetime.datetime(2022, 4, 17, 9, 45, 1, 116000, tzinfo=tzlocal()),\n",
       "   'EndTime': datetime.datetime(2022, 4, 17, 9, 45, 1, 116000, tzinfo=tzlocal()),\n",
       "   'StatusMessage': 'Training job completed'}],\n",
       " 'FinalMetricDataList': [{'MetricName': 'train:rmse:epoch',\n",
       "   'Value': 0.3992254137992859,\n",
       "   'Timestamp': datetime.datetime(2022, 4, 17, 9, 43, 24, tzinfo=tzlocal())},\n",
       "  {'MetricName': 'train:progress',\n",
       "   'Value': 100.0,\n",
       "   'Timestamp': datetime.datetime(2022, 4, 17, 9, 43, 24, tzinfo=tzlocal())},\n",
       "  {'MetricName': 'test:mse',\n",
       "   'Value': 0.1881229430437088,\n",
       "   'Timestamp': datetime.datetime(2022, 4, 17, 9, 44, 19, tzinfo=tzlocal())},\n",
       "  {'MetricName': 'train:mse:batch',\n",
       "   'Value': 0.16018961369991302,\n",
       "   'Timestamp': datetime.datetime(2022, 4, 17, 9, 43, 8, tzinfo=tzlocal())},\n",
       "  {'MetricName': 'train:absolute_loss:epoch',\n",
       "   'Value': 0.2516639530658722,\n",
       "   'Timestamp': datetime.datetime(2022, 4, 17, 9, 43, 24, tzinfo=tzlocal())},\n",
       "  {'MetricName': 'test:absolute_loss',\n",
       "   'Value': 0.28371772170066833,\n",
       "   'Timestamp': datetime.datetime(2022, 4, 17, 9, 44, 19, tzinfo=tzlocal())},\n",
       "  {'MetricName': 'train:mse',\n",
       "   'Value': 0.1593809276819229,\n",
       "   'Timestamp': datetime.datetime(2022, 4, 17, 9, 43, 24, tzinfo=tzlocal())},\n",
       "  {'MetricName': 'train:mse:epoch',\n",
       "   'Value': 0.1593809276819229,\n",
       "   'Timestamp': datetime.datetime(2022, 4, 17, 9, 43, 24, tzinfo=tzlocal())},\n",
       "  {'MetricName': 'train:rmse:batch',\n",
       "   'Value': 0.40023696422576904,\n",
       "   'Timestamp': datetime.datetime(2022, 4, 17, 9, 43, 8, tzinfo=tzlocal())},\n",
       "  {'MetricName': 'train:rmse',\n",
       "   'Value': 0.3992254137992859,\n",
       "   'Timestamp': datetime.datetime(2022, 4, 17, 9, 43, 24, tzinfo=tzlocal())},\n",
       "  {'MetricName': 'test:rmse',\n",
       "   'Value': 0.43373140692710876,\n",
       "   'Timestamp': datetime.datetime(2022, 4, 17, 9, 44, 19, tzinfo=tzlocal())},\n",
       "  {'MetricName': 'train:absolute_loss:batch',\n",
       "   'Value': 0.2525309920310974,\n",
       "   'Timestamp': datetime.datetime(2022, 4, 17, 9, 43, 8, tzinfo=tzlocal())},\n",
       "  {'MetricName': 'train:absolute_loss',\n",
       "   'Value': 0.2516639530658722,\n",
       "   'Timestamp': datetime.datetime(2022, 4, 17, 9, 43, 24, tzinfo=tzlocal())},\n",
       "  {'MetricName': 'train:throughput',\n",
       "   'Value': 42228.49609375,\n",
       "   'Timestamp': datetime.datetime(2022, 4, 17, 9, 43, 24, tzinfo=tzlocal())}],\n",
       " 'EnableNetworkIsolation': False,\n",
       " 'EnableInterContainerTrafficEncryption': False,\n",
       " 'EnableManagedSpotTraining': False,\n",
       " 'TrainingTimeInSeconds': 505,\n",
       " 'BillableTimeInSeconds': 505,\n",
       " 'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-ap-south-1-659144925604/filteredfm/output',\n",
       "  'ProfilingIntervalInMilliseconds': 500},\n",
       " 'ProfilerRuleConfigurations': [{'RuleConfigurationName': 'ProfilerReport-1650188091',\n",
       "   'RuleEvaluatorImage': '904829902805.dkr.ecr.ap-south-1.amazonaws.com/sagemaker-debugger-rules:latest',\n",
       "   'VolumeSizeInGB': 0,\n",
       "   'RuleParameters': {'rule_to_invoke': 'ProfilerReport'}}],\n",
       " 'ProfilerRuleEvaluationStatuses': [{'RuleConfigurationName': 'ProfilerReport-1650188091',\n",
       "   'RuleEvaluationJobArn': 'arn:aws:sagemaker:ap-south-1:659144925604:processing-job/fm-job-recommender-v1-2022-profilerreport-1650188091-665cd224',\n",
       "   'RuleEvaluationStatus': 'NoIssuesFound',\n",
       "   'LastModifiedTime': datetime.datetime(2022, 4, 17, 9, 45, 17, 62000, tzinfo=tzlocal())}],\n",
       " 'ProfilingStatus': 'Enabled',\n",
       " 'ResponseMetadata': {'RequestId': 'fa5c883b-b08a-4d7d-8515-d099188c0f74',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'fa5c883b-b08a-4d7d-8515-d099188c0f74',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '8155',\n",
       "   'date': 'Sun, 17 Apr 2022 09:45:39 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = estimator.latest_training_job.job_name\n",
    "\n",
    "sagemaker_boto_client = boto3.Session(region_name=region).client(\"sagemaker\")\n",
    "training_job_info = sagemaker_boto_client.describe_training_job(TrainingJobName = job_name)\n",
    "training_job_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the serializer and desrializer for prediction request and parsing response. this will be used by inference endpoint for request and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "import json\n",
    "\n",
    "class fm_json_serializer(JSONSerializer):\n",
    "    def serialize(self, data):\n",
    "        js = {\"instances\": []}\n",
    "        for row in data:\n",
    "            js[\"instances\"].append({\"features\": row.tolist()})\n",
    "        return json.dumps(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count = 1,\n",
    "                             instance_type = \"ml.m5.xlarge\",\n",
    "                             endpoint_name = job_name,\n",
    "                             serializer = fm_json_serializer(),\n",
    "                             deserializer = JSONDeserializer(),\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a sample data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>unique_customers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>706016001</td>\n",
       "      <td>13238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>759871002</td>\n",
       "      <td>10717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>610776002</td>\n",
       "      <td>10699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>720125001</td>\n",
       "      <td>10626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>372860001</td>\n",
       "      <td>10173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>750330003</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>570004009</td>\n",
       "      <td>907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>189634001</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>717464002</td>\n",
       "      <td>853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>565379002</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1684 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      article_id  unique_customers\n",
       "0      706016001             13238\n",
       "1      759871002             10717\n",
       "2      610776002             10699\n",
       "3      720125001             10626\n",
       "4      372860001             10173\n",
       "...          ...               ...\n",
       "1679   750330003               916\n",
       "1680   570004009               907\n",
       "1681   189634001               882\n",
       "1682   717464002               853\n",
       "1683   565379002               841\n",
       "\n",
       "[1684 rows x 2 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trending = df_rank.copy()\n",
    "trending = (trending.groupby([\"article_id\"])\n",
    "            .nunique()[\"customer_id\"]\n",
    "            .sort_values(ascending=False)\n",
    "            .reset_index()            \n",
    "           )            \n",
    "trending = trending.rename(columns={'customer_id': 'unique_customers'})\n",
    "trending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample=df_rank.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_sample['article_id']=706016001\n",
    "df_sample['customer_id']=13592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>detail_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13592</td>\n",
       "      <td>706016001</td>\n",
       "      <td>1</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>Fitted, long-sleeved, polo-neck top in soft je...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  customer_id  article_id  rating  product_group_name  \\\n",
       "0      0        13592   706016001       1  Garment Upper body   \n",
       "\n",
       "                                         detail_desc  \n",
       "0  Fitted, long-sleeved, polo-neck top in soft je...  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the sparse matrix using the One hot encoding and tfidf for the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x682272 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ohe = OneHotEncoder(handle_unknown = \"ignore\")\n",
    "# ohe_cols = [\"customer_id\", \"article_id\"]\n",
    "# ohe.fit(df[ohe_cols])\n",
    "ohe_features = ohe.transform(df_sample[ohe_cols])\n",
    "ohe_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x482 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_sample = vectorizer.transform(df_sample[\"detail_desc\"])\n",
    "tfidf_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trending = hstack([ohe_features,tfidf_sample], format=\"csr\", dtype=\"float32\")\n",
    "X_trending.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the prediction for the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'score': 1.1960450410842896}]}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = predictor.predict(X_trending.toarray())\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have deployed recommendation model based on Sagemaker inbuilt Factorization machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets prepare the data for the inference job. Lets pick 15 random customer and 15 most popular items\n",
    "### Then we will create input data as each customer and item combination (10*10 combinations)\n",
    "### Then use this data to get the ranking for each combination\n",
    "### For each customer we can arrange data for top picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_int=pd.DataFrame(pd.read_csv(\"input_customers_rec.csv\")[\"customer_id\"]).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_items=pd.DataFrame(pd.read_csv(\"popular_items.csv\").article_id).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['customer_id'], dtype='object')\n",
      "Index(['article_id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(customers_int.columns)\n",
    "print(pop_items.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_int['key'] = 1\n",
    "pop_items['key'] = 1\n",
    "  \n",
    "# to obtain the cross join we will merge \n",
    "# on the key and drop it.\n",
    "batch_input = pd.merge(customers_int, pop_items, on ='key').drop(\"key\", 1)\n",
    "  \n",
    "batch_input.to_csv(\"batch_input.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the items metadata for input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>prod_name</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_no</th>\n",
       "      <th>graphical_appearance_name</th>\n",
       "      <th>colour_group_code</th>\n",
       "      <th>colour_group_name</th>\n",
       "      <th>perceived_colour_value_id</th>\n",
       "      <th>perceived_colour_value_name</th>\n",
       "      <th>perceived_colour_master_id</th>\n",
       "      <th>perceived_colour_master_name</th>\n",
       "      <th>department_no</th>\n",
       "      <th>department_name</th>\n",
       "      <th>index_code</th>\n",
       "      <th>index_name</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>index_group_name</th>\n",
       "      <th>section_no</th>\n",
       "      <th>section_name</th>\n",
       "      <th>garment_group_no</th>\n",
       "      <th>garment_group_name</th>\n",
       "      <th>detail_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108775015</td>\n",
       "      <td>108775</td>\n",
       "      <td>Strap top</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>4</td>\n",
       "      <td>Dark</td>\n",
       "      <td>5</td>\n",
       "      <td>Black</td>\n",
       "      <td>1676</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>16</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108775044</td>\n",
       "      <td>108775</td>\n",
       "      <td>Strap top</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>10</td>\n",
       "      <td>White</td>\n",
       "      <td>3</td>\n",
       "      <td>Light</td>\n",
       "      <td>9</td>\n",
       "      <td>White</td>\n",
       "      <td>1676</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>16</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108775051</td>\n",
       "      <td>108775</td>\n",
       "      <td>Strap top (1)</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010017</td>\n",
       "      <td>Stripe</td>\n",
       "      <td>11</td>\n",
       "      <td>Off White</td>\n",
       "      <td>1</td>\n",
       "      <td>Dusty Light</td>\n",
       "      <td>9</td>\n",
       "      <td>White</td>\n",
       "      <td>1676</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>16</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Jersey top with narrow shoulder straps.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110065001</td>\n",
       "      <td>110065</td>\n",
       "      <td>OP T-shirt (Idro)</td>\n",
       "      <td>306</td>\n",
       "      <td>Bra</td>\n",
       "      <td>Underwear</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>4</td>\n",
       "      <td>Dark</td>\n",
       "      <td>5</td>\n",
       "      <td>Black</td>\n",
       "      <td>1339</td>\n",
       "      <td>Clean Lingerie</td>\n",
       "      <td>B</td>\n",
       "      <td>Lingeries/Tights</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>61</td>\n",
       "      <td>Womens Lingerie</td>\n",
       "      <td>1017</td>\n",
       "      <td>Under-, Nightwear</td>\n",
       "      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110065002</td>\n",
       "      <td>110065</td>\n",
       "      <td>OP T-shirt (Idro)</td>\n",
       "      <td>306</td>\n",
       "      <td>Bra</td>\n",
       "      <td>Underwear</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>10</td>\n",
       "      <td>White</td>\n",
       "      <td>3</td>\n",
       "      <td>Light</td>\n",
       "      <td>9</td>\n",
       "      <td>White</td>\n",
       "      <td>1339</td>\n",
       "      <td>Clean Lingerie</td>\n",
       "      <td>B</td>\n",
       "      <td>Lingeries/Tights</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>61</td>\n",
       "      <td>Womens Lingerie</td>\n",
       "      <td>1017</td>\n",
       "      <td>Under-, Nightwear</td>\n",
       "      <td>Microfibre T-shirt bra with underwired, moulde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  product_code          prod_name  product_type_no  \\\n",
       "0   108775015        108775          Strap top              253   \n",
       "1   108775044        108775          Strap top              253   \n",
       "2   108775051        108775      Strap top (1)              253   \n",
       "3   110065001        110065  OP T-shirt (Idro)              306   \n",
       "4   110065002        110065  OP T-shirt (Idro)              306   \n",
       "\n",
       "  product_type_name  product_group_name  graphical_appearance_no  \\\n",
       "0          Vest top  Garment Upper body                  1010016   \n",
       "1          Vest top  Garment Upper body                  1010016   \n",
       "2          Vest top  Garment Upper body                  1010017   \n",
       "3               Bra           Underwear                  1010016   \n",
       "4               Bra           Underwear                  1010016   \n",
       "\n",
       "  graphical_appearance_name  colour_group_code colour_group_name  \\\n",
       "0                     Solid                  9             Black   \n",
       "1                     Solid                 10             White   \n",
       "2                    Stripe                 11         Off White   \n",
       "3                     Solid                  9             Black   \n",
       "4                     Solid                 10             White   \n",
       "\n",
       "   perceived_colour_value_id perceived_colour_value_name  \\\n",
       "0                          4                        Dark   \n",
       "1                          3                       Light   \n",
       "2                          1                 Dusty Light   \n",
       "3                          4                        Dark   \n",
       "4                          3                       Light   \n",
       "\n",
       "   perceived_colour_master_id perceived_colour_master_name  department_no  \\\n",
       "0                           5                        Black           1676   \n",
       "1                           9                        White           1676   \n",
       "2                           9                        White           1676   \n",
       "3                           5                        Black           1339   \n",
       "4                           9                        White           1339   \n",
       "\n",
       "  department_name index_code        index_name  index_group_no  \\\n",
       "0    Jersey Basic          A        Ladieswear               1   \n",
       "1    Jersey Basic          A        Ladieswear               1   \n",
       "2    Jersey Basic          A        Ladieswear               1   \n",
       "3  Clean Lingerie          B  Lingeries/Tights               1   \n",
       "4  Clean Lingerie          B  Lingeries/Tights               1   \n",
       "\n",
       "  index_group_name  section_no            section_name  garment_group_no  \\\n",
       "0       Ladieswear          16  Womens Everyday Basics              1002   \n",
       "1       Ladieswear          16  Womens Everyday Basics              1002   \n",
       "2       Ladieswear          16  Womens Everyday Basics              1002   \n",
       "3       Ladieswear          61         Womens Lingerie              1017   \n",
       "4       Ladieswear          61         Womens Lingerie              1017   \n",
       "\n",
       "  garment_group_name                                        detail_desc  \n",
       "0       Jersey Basic            Jersey top with narrow shoulder straps.  \n",
       "1       Jersey Basic            Jersey top with narrow shoulder straps.  \n",
       "2       Jersey Basic            Jersey top with narrow shoulder straps.  \n",
       "3  Under-, Nightwear  Microfibre T-shirt bra with underwired, moulde...  \n",
       "4  Under-, Nightwear  Microfibre T-shirt bra with underwired, moulde...  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_key_art = 'kaggle/articles.csv'\n",
    "obj_art = s3_client.get_object(Bucket=bucket, Key=file_key_art)\n",
    "df_articles = pd.read_csv(io.BytesIO(obj_art['Body'].read()))\n",
    "df_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>product_code</th>\n",
       "      <th>prod_name</th>\n",
       "      <th>product_type_no</th>\n",
       "      <th>product_type_name</th>\n",
       "      <th>product_group_name</th>\n",
       "      <th>graphical_appearance_no</th>\n",
       "      <th>graphical_appearance_name</th>\n",
       "      <th>colour_group_code</th>\n",
       "      <th>colour_group_name</th>\n",
       "      <th>perceived_colour_value_id</th>\n",
       "      <th>perceived_colour_value_name</th>\n",
       "      <th>perceived_colour_master_id</th>\n",
       "      <th>perceived_colour_master_name</th>\n",
       "      <th>department_no</th>\n",
       "      <th>department_name</th>\n",
       "      <th>index_code</th>\n",
       "      <th>index_name</th>\n",
       "      <th>index_group_no</th>\n",
       "      <th>index_group_name</th>\n",
       "      <th>section_no</th>\n",
       "      <th>section_name</th>\n",
       "      <th>garment_group_no</th>\n",
       "      <th>garment_group_name</th>\n",
       "      <th>detail_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>115966</td>\n",
       "      <td>706016001</td>\n",
       "      <td>706016</td>\n",
       "      <td>Jade HW Skinny Denim TRS</td>\n",
       "      <td>272</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>4</td>\n",
       "      <td>Dark</td>\n",
       "      <td>5</td>\n",
       "      <td>Black</td>\n",
       "      <td>1747</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>D</td>\n",
       "      <td>Divided</td>\n",
       "      <td>2</td>\n",
       "      <td>Divided</td>\n",
       "      <td>53</td>\n",
       "      <td>Divided Collection</td>\n",
       "      <td>1009</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>High-waisted jeans in washed superstretch deni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>115966</td>\n",
       "      <td>610776002</td>\n",
       "      <td>610776</td>\n",
       "      <td>Tilly (1)</td>\n",
       "      <td>255</td>\n",
       "      <td>T-shirt</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>4</td>\n",
       "      <td>Dark</td>\n",
       "      <td>5</td>\n",
       "      <td>Black</td>\n",
       "      <td>1676</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>16</td>\n",
       "      <td>Womens Everyday Basics</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>T-shirt in lightweight jersey with a rounded h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>115966</td>\n",
       "      <td>751471001</td>\n",
       "      <td>751471</td>\n",
       "      <td>Pluto RW slacks (1)</td>\n",
       "      <td>272</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>4</td>\n",
       "      <td>Dark</td>\n",
       "      <td>5</td>\n",
       "      <td>Black</td>\n",
       "      <td>1722</td>\n",
       "      <td>Trouser</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>15</td>\n",
       "      <td>Womens Everyday Collection</td>\n",
       "      <td>1009</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>Ankle-length cigarette trousers in a stretch w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>115966</td>\n",
       "      <td>759871002</td>\n",
       "      <td>759871</td>\n",
       "      <td>Tilda tank</td>\n",
       "      <td>253</td>\n",
       "      <td>Vest top</td>\n",
       "      <td>Garment Upper body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>4</td>\n",
       "      <td>Dark</td>\n",
       "      <td>5</td>\n",
       "      <td>Black</td>\n",
       "      <td>3936</td>\n",
       "      <td>EQ Divided Basics</td>\n",
       "      <td>D</td>\n",
       "      <td>Divided</td>\n",
       "      <td>2</td>\n",
       "      <td>Divided</td>\n",
       "      <td>80</td>\n",
       "      <td>Divided Complements Other</td>\n",
       "      <td>1002</td>\n",
       "      <td>Jersey Basic</td>\n",
       "      <td>Cropped, fitted top in cotton jersey with narr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>115966</td>\n",
       "      <td>720125001</td>\n",
       "      <td>720125</td>\n",
       "      <td>SUPREME RW tights</td>\n",
       "      <td>273</td>\n",
       "      <td>Leggings/Tights</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>9</td>\n",
       "      <td>Black</td>\n",
       "      <td>4</td>\n",
       "      <td>Dark</td>\n",
       "      <td>5</td>\n",
       "      <td>Black</td>\n",
       "      <td>8310</td>\n",
       "      <td>Ladies Sport Bottoms</td>\n",
       "      <td>S</td>\n",
       "      <td>Sport</td>\n",
       "      <td>26</td>\n",
       "      <td>Sport</td>\n",
       "      <td>5</td>\n",
       "      <td>Ladies H&amp;M Sport</td>\n",
       "      <td>1005</td>\n",
       "      <td>Jersey Fancy</td>\n",
       "      <td>Sports tights in fast-drying functional fabric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>220</td>\n",
       "      <td>214566</td>\n",
       "      <td>706016002</td>\n",
       "      <td>706016</td>\n",
       "      <td>Jade HW Skinny Denim TRS</td>\n",
       "      <td>272</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>71</td>\n",
       "      <td>Light Blue</td>\n",
       "      <td>3</td>\n",
       "      <td>Light</td>\n",
       "      <td>2</td>\n",
       "      <td>Blue</td>\n",
       "      <td>1747</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>D</td>\n",
       "      <td>Divided</td>\n",
       "      <td>2</td>\n",
       "      <td>Divided</td>\n",
       "      <td>53</td>\n",
       "      <td>Divided Collection</td>\n",
       "      <td>1009</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>High-waisted jeans in washed superstretch deni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>221</td>\n",
       "      <td>214566</td>\n",
       "      <td>599580055</td>\n",
       "      <td>599580</td>\n",
       "      <td>Timeless Midrise Brief</td>\n",
       "      <td>59</td>\n",
       "      <td>Swimwear bottom</td>\n",
       "      <td>Swimwear</td>\n",
       "      <td>1010006</td>\n",
       "      <td>Dot</td>\n",
       "      <td>93</td>\n",
       "      <td>Dark Green</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium Dusty</td>\n",
       "      <td>19</td>\n",
       "      <td>Green</td>\n",
       "      <td>4242</td>\n",
       "      <td>Swimwear</td>\n",
       "      <td>B</td>\n",
       "      <td>Lingeries/Tights</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>60</td>\n",
       "      <td>Womens Swimwear, beachwear</td>\n",
       "      <td>1018</td>\n",
       "      <td>Swimwear</td>\n",
       "      <td>Fully lined bikini bottoms with a mid waist an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>222</td>\n",
       "      <td>214566</td>\n",
       "      <td>448509014</td>\n",
       "      <td>448509</td>\n",
       "      <td>Perrie Slim Mom Denim TRS</td>\n",
       "      <td>272</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010016</td>\n",
       "      <td>Solid</td>\n",
       "      <td>72</td>\n",
       "      <td>Blue</td>\n",
       "      <td>3</td>\n",
       "      <td>Light</td>\n",
       "      <td>2</td>\n",
       "      <td>Blue</td>\n",
       "      <td>1747</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>D</td>\n",
       "      <td>Divided</td>\n",
       "      <td>2</td>\n",
       "      <td>Divided</td>\n",
       "      <td>53</td>\n",
       "      <td>Divided Collection</td>\n",
       "      <td>1009</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>5-pocket, ankle-length jeans in washed, sturdy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>223</td>\n",
       "      <td>214566</td>\n",
       "      <td>741356002</td>\n",
       "      <td>741356</td>\n",
       "      <td>Pamela Shorts HW</td>\n",
       "      <td>274</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010023</td>\n",
       "      <td>Denim</td>\n",
       "      <td>72</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium Dusty</td>\n",
       "      <td>2</td>\n",
       "      <td>Blue</td>\n",
       "      <td>1723</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>A</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>1</td>\n",
       "      <td>Ladieswear</td>\n",
       "      <td>15</td>\n",
       "      <td>Womens Everyday Collection</td>\n",
       "      <td>1025</td>\n",
       "      <td>Shorts</td>\n",
       "      <td>Short, 5-pocket shorts in washed denim with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>224</td>\n",
       "      <td>214566</td>\n",
       "      <td>714790020</td>\n",
       "      <td>714790</td>\n",
       "      <td>Mom Fit Ultra HW</td>\n",
       "      <td>272</td>\n",
       "      <td>Trousers</td>\n",
       "      <td>Garment Lower body</td>\n",
       "      <td>1010023</td>\n",
       "      <td>Denim</td>\n",
       "      <td>72</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium Dusty</td>\n",
       "      <td>2</td>\n",
       "      <td>Blue</td>\n",
       "      <td>1772</td>\n",
       "      <td>Denim Trousers</td>\n",
       "      <td>D</td>\n",
       "      <td>Divided</td>\n",
       "      <td>2</td>\n",
       "      <td>Divided</td>\n",
       "      <td>57</td>\n",
       "      <td>Ladies Denim</td>\n",
       "      <td>1016</td>\n",
       "      <td>Trousers Denim</td>\n",
       "      <td>5-pocket, ankle-length jeans in washed, stretc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  customer_id  article_id  product_code                  prod_name  \\\n",
       "0        0       115966   706016001        706016   Jade HW Skinny Denim TRS   \n",
       "1        1       115966   610776002        610776                  Tilly (1)   \n",
       "2        2       115966   751471001        751471        Pluto RW slacks (1)   \n",
       "3        3       115966   759871002        759871                 Tilda tank   \n",
       "4        4       115966   720125001        720125          SUPREME RW tights   \n",
       "..     ...          ...         ...           ...                        ...   \n",
       "220    220       214566   706016002        706016   Jade HW Skinny Denim TRS   \n",
       "221    221       214566   599580055        599580     Timeless Midrise Brief   \n",
       "222    222       214566   448509014        448509  Perrie Slim Mom Denim TRS   \n",
       "223    223       214566   741356002        741356           Pamela Shorts HW   \n",
       "224    224       214566   714790020        714790           Mom Fit Ultra HW   \n",
       "\n",
       "     product_type_no product_type_name  product_group_name  \\\n",
       "0                272          Trousers  Garment Lower body   \n",
       "1                255           T-shirt  Garment Upper body   \n",
       "2                272          Trousers  Garment Lower body   \n",
       "3                253          Vest top  Garment Upper body   \n",
       "4                273   Leggings/Tights  Garment Lower body   \n",
       "..               ...               ...                 ...   \n",
       "220              272          Trousers  Garment Lower body   \n",
       "221               59   Swimwear bottom            Swimwear   \n",
       "222              272          Trousers  Garment Lower body   \n",
       "223              274            Shorts  Garment Lower body   \n",
       "224              272          Trousers  Garment Lower body   \n",
       "\n",
       "     graphical_appearance_no graphical_appearance_name  colour_group_code  \\\n",
       "0                    1010016                     Solid                  9   \n",
       "1                    1010016                     Solid                  9   \n",
       "2                    1010016                     Solid                  9   \n",
       "3                    1010016                     Solid                  9   \n",
       "4                    1010016                     Solid                  9   \n",
       "..                       ...                       ...                ...   \n",
       "220                  1010016                     Solid                 71   \n",
       "221                  1010006                       Dot                 93   \n",
       "222                  1010016                     Solid                 72   \n",
       "223                  1010023                     Denim                 72   \n",
       "224                  1010023                     Denim                 72   \n",
       "\n",
       "    colour_group_name  perceived_colour_value_id perceived_colour_value_name  \\\n",
       "0               Black                          4                        Dark   \n",
       "1               Black                          4                        Dark   \n",
       "2               Black                          4                        Dark   \n",
       "3               Black                          4                        Dark   \n",
       "4               Black                          4                        Dark   \n",
       "..                ...                        ...                         ...   \n",
       "220        Light Blue                          3                       Light   \n",
       "221        Dark Green                          2                Medium Dusty   \n",
       "222              Blue                          3                       Light   \n",
       "223              Blue                          2                Medium Dusty   \n",
       "224              Blue                          2                Medium Dusty   \n",
       "\n",
       "     perceived_colour_master_id perceived_colour_master_name  department_no  \\\n",
       "0                             5                        Black           1747   \n",
       "1                             5                        Black           1676   \n",
       "2                             5                        Black           1722   \n",
       "3                             5                        Black           3936   \n",
       "4                             5                        Black           8310   \n",
       "..                          ...                          ...            ...   \n",
       "220                           2                         Blue           1747   \n",
       "221                          19                        Green           4242   \n",
       "222                           2                         Blue           1747   \n",
       "223                           2                         Blue           1723   \n",
       "224                           2                         Blue           1772   \n",
       "\n",
       "          department_name index_code        index_name  index_group_no  \\\n",
       "0                Trousers          D           Divided               2   \n",
       "1            Jersey Basic          A        Ladieswear               1   \n",
       "2                 Trouser          A        Ladieswear               1   \n",
       "3       EQ Divided Basics          D           Divided               2   \n",
       "4    Ladies Sport Bottoms          S             Sport              26   \n",
       "..                    ...        ...               ...             ...   \n",
       "220              Trousers          D           Divided               2   \n",
       "221              Swimwear          B  Lingeries/Tights               1   \n",
       "222              Trousers          D           Divided               2   \n",
       "223                Shorts          A        Ladieswear               1   \n",
       "224        Denim Trousers          D           Divided               2   \n",
       "\n",
       "    index_group_name  section_no                section_name  \\\n",
       "0            Divided          53          Divided Collection   \n",
       "1         Ladieswear          16      Womens Everyday Basics   \n",
       "2         Ladieswear          15  Womens Everyday Collection   \n",
       "3            Divided          80   Divided Complements Other   \n",
       "4              Sport           5            Ladies H&M Sport   \n",
       "..               ...         ...                         ...   \n",
       "220          Divided          53          Divided Collection   \n",
       "221       Ladieswear          60  Womens Swimwear, beachwear   \n",
       "222          Divided          53          Divided Collection   \n",
       "223       Ladieswear          15  Womens Everyday Collection   \n",
       "224          Divided          57                Ladies Denim   \n",
       "\n",
       "     garment_group_no garment_group_name  \\\n",
       "0                1009           Trousers   \n",
       "1                1002       Jersey Basic   \n",
       "2                1009           Trousers   \n",
       "3                1002       Jersey Basic   \n",
       "4                1005       Jersey Fancy   \n",
       "..                ...                ...   \n",
       "220              1009           Trousers   \n",
       "221              1018           Swimwear   \n",
       "222              1009           Trousers   \n",
       "223              1025             Shorts   \n",
       "224              1016     Trousers Denim   \n",
       "\n",
       "                                           detail_desc  \n",
       "0    High-waisted jeans in washed superstretch deni...  \n",
       "1    T-shirt in lightweight jersey with a rounded h...  \n",
       "2    Ankle-length cigarette trousers in a stretch w...  \n",
       "3    Cropped, fitted top in cotton jersey with narr...  \n",
       "4    Sports tights in fast-drying functional fabric...  \n",
       "..                                                 ...  \n",
       "220  High-waisted jeans in washed superstretch deni...  \n",
       "221  Fully lined bikini bottoms with a mid waist an...  \n",
       "222  5-pocket, ankle-length jeans in washed, sturdy...  \n",
       "223  Short, 5-pocket shorts in washed denim with a ...  \n",
       "224  5-pocket, ankle-length jeans in washed, stretc...  \n",
       "\n",
       "[225 rows x 27 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_input_meta=pd.merge(batch_input,df_articles,on='article_id',how='left').reset_index()\n",
    "batch_input_meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For input sparse data use same One Hot Encoder and TFIDF vectorizer from the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.1834833 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.17198625,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_features = ohe.transform(batch_input_meta[ohe_cols])\n",
    "\n",
    "tfidf_sample = vectorizer.transform(batch_input_meta[\"detail_desc\"])\n",
    "\n",
    "X_batch = hstack([ohe_features,tfidf_sample], format=\"csr\", dtype=\"float32\")\n",
    "X_batch.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save sparse data in recordio protobuf format and save in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_sparse_recordio_file(\"batch_input.recordio\", X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker version: 2.70.0\n",
      "Region: ap-south-1\n",
      "Bucket: sagemaker-ap-south-1-659144925604\n",
      "train file location: s3://sagemaker-ap-south-1-659144925604/batchfilter/batch_input.recordio\n"
     ]
    }
   ],
   "source": [
    "prefix = \"batchfilter\"\n",
    "input_key = \"batch_input.recordio\"\n",
    "output_location = f\"s3://{bucket}/{prefix}/output\"\n",
    "\n",
    "batch_file_location = upload_to_s3(\"batch_input.recordio\", bucket, prefix, input_key)\n",
    "\n",
    "print(\"SageMaker version:\", sagemaker.__version__)\n",
    "print(\"Region:\", region)\n",
    "print(\"Bucket:\", bucket)\n",
    "print(\"train file location:\", batch_file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the batch transform job and retrieve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_transformer = estimator.transformer(\n",
    "    instance_type='ml.c4.xlarge', \n",
    "    instance_count=1, \n",
    "    strategy=\"MultiRecord\", \n",
    "    output_path=\"s3://{}/transform/\".format(bucket)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................\u001b[34mDocker entrypoint called with argument(s): serve\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/jsonref.py:8: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Mapping, MutableMapping, Sequence\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:87: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/algorithm/network_builder.py:120: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/google/protobuf/internal/api_implementation.py:151: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from google.protobuf.pyext import _message\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] loaded entry point class algorithm.serve.server_config:config_api\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] loading entry points\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/ai_algorithms_sdk/serve.py:221: DeprecationWarning: entrypoint algorithm.request_iterators is deprecated in favor of algorithm.io.data_handlers.serve\n",
      "  \"in favor of algorithm.io.data_handlers.serve\", DeprecationWarning)\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] loaded request iterator application/json\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] loaded request iterator application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] loaded request iterator application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] loaded response encoder application/json\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] loaded response encoder application/jsonlines\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] loaded response encoder application/x-recordio-protobuf\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] loaded entry point class algorithm:model\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] Model Size: 188444294 bytes\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] Number of vCPUs: 4\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] Number of server workers: 4\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:53:00 +0000] [1] [INFO] Starting gunicorn 20.1.0\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:53:00 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:53:00 +0000] [1] [INFO] Using worker: sync\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:53:00 +0000] [31] [INFO] Booting worker with pid: 31\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] loading model...\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:53:00 +0000] [32] [INFO] Booting worker with pid: 32\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] loading model...\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:53:00 +0000] [33] [INFO] Booting worker with pid: 33\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] loading model...\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:53:00 +0000] [34] [INFO] Booting worker with pid: 34\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:00 INFO 140146484217664] loading model...\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 WARNING 140146484217664] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 WARNING 140146484217664] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 WARNING 140146484217664] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 WARNING 140146484217664] Requesting context without setting the requested num of gpus. Using 'auto'\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] nvidia-smi: took 0.031 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] nvidia-smi: took 0.032 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] nvidia-smi: took 0.032 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] nvidia-smi: took 0.037 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] Loading regression model.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] ...model loaded.\u001b[0m\n",
      "\u001b[35m[04/17/2022 09:53:03 INFO 140146484217664] Loading regression model.\u001b[0m\n",
      "\u001b[35m[04/17/2022 09:53:03 INFO 140146484217664] ...model loaded.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] Loading regression model.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] ...model loaded.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] Loading regression model.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] ...model loaded.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] Loading regression model.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:03 INFO 140146484217664] ...model loaded.\u001b[0m\n",
      "\u001b[35m[04/17/2022 09:53:03 INFO 140146484217664] Loading regression model.\u001b[0m\n",
      "\u001b[35m[04/17/2022 09:53:03 INFO 140146484217664] ...model loaded.\u001b[0m\n",
      "\u001b[35m[04/17/2022 09:53:03 INFO 140146484217664] Loading regression model.\u001b[0m\n",
      "\u001b[35m[04/17/2022 09:53:03 INFO 140146484217664] ...model loaded.\u001b[0m\n",
      "\u001b[35m[04/17/2022 09:53:03 INFO 140146484217664] Loading regression model.\u001b[0m\n",
      "\u001b[35m[04/17/2022 09:53:03 INFO 140146484217664] ...model loaded.\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:05 INFO 140146484217664] Model Size: 188444294 bytes\u001b[0m\n",
      "\u001b[34m[04/17/2022 09:53:05 INFO 140146484217664] Number of vCPUs: 4\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650189183.3761828, \"EndTime\": 1650189185.4346428, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/mxnet/module/base_module.py:65: UserWarning: Data provided by label_shapes don't match names specified by label_names ([] vs. ['out_label'])\n",
      "  warnings.warn(msg)\u001b[0m\n",
      "\u001b[34m[2022-04-17 09:53:05.920] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/tmp/tmpmommn1vf/tmpc884t0tt\", \"epoch\": 0, \"duration\": 374, \"num_examples\": 1, \"num_bytes\": 35896}\u001b[0m\n",
      "\u001b[35m[04/17/2022 09:53:05 INFO 140146484217664] Model Size: 188444294 bytes\u001b[0m\n",
      "\u001b[35m[04/17/2022 09:53:05 INFO 140146484217664] Number of vCPUs: 4\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1650189183.3761828, \"EndTime\": 1650189185.4346428, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"execution_parameters.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/mxnet/module/base_module.py:65: UserWarning: Data provided by label_shapes don't match names specified by label_names ([] vs. ['out_label'])\n",
      "  warnings.warn(msg)\u001b[0m\n",
      "\u001b[35m[2022-04-17 09:53:05.920] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/tmp/tmpmommn1vf/tmpc884t0tt\", \"epoch\": 0, \"duration\": 374, \"num_examples\": 1, \"num_bytes\": 35896}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1650189183.312857, \"EndTime\": 1650189185.9231038, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[35m#metrics {\"StartTime\": 1650189183.312857, \"EndTime\": 1650189185.9231038, \"Dimensions\": {\"Algorithm\": \"AlgorithmModel\", \"Host\": \"UNKNOWN\", \"Operation\": \"scoring\"}, \"Metrics\": {\"invocations.count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}}}\u001b[0m\n",
      "\u001b[32m2022-04-17T09:53:05.439:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fm_transformer.transform(\n",
    "    data=\"s3://{}/batchfilter/\".format(bucket), \n",
    "    data_type='S3Prefix', \n",
    "    content_type=\"application/x-recordio-protobuf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_from_s3(bucket, key):\n",
    "    s3 = boto3.resource('s3')\n",
    "    obj = s3.Object( bucket, key)\n",
    "    content = obj.get()['Body'].read()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'transform/batch_input.recordio.out'\n",
    "response = download_from_s3(bucket, key)\n",
    "result = [json.loads(row)[\"score\"] for row in response.split(b\"\\n\") if len(row) > 0]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 1)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_batch=pd.DataFrame(result)\n",
    "result_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result=batch_input.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result[\"score\"]=result_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115966</td>\n",
       "      <td>706016001</td>\n",
       "      <td>1.429199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115966</td>\n",
       "      <td>610776002</td>\n",
       "      <td>1.307121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115966</td>\n",
       "      <td>751471001</td>\n",
       "      <td>1.334001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115966</td>\n",
       "      <td>759871002</td>\n",
       "      <td>1.216511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>115966</td>\n",
       "      <td>720125001</td>\n",
       "      <td>1.192747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  article_id     score\n",
       "0       115966   706016001  1.429199\n",
       "1       115966   610776002  1.307121\n",
       "2       115966   751471001  1.334001\n",
       "3       115966   759871002  1.216511\n",
       "4       115966   720125001  1.192747"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-south-1:394103062818:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
